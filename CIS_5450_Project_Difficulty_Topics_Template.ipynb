{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7fXCyFHPr3X"
      },
      "source": [
        "# CIS 5450 Project: Difficulty Topics\n",
        "**Team Members:** Prithvi Seshadri, Vamsi Krishna, Anaya Choudhari\n",
        "## Video Link: [Project Presentation Video](https://drive.google.com/file/d/1Wq_g_4Nbs5JRGb5VOnJ73Qawm4WYkICU/view?usp=sharing)\n",
        "\n",
        "> This notebook documents how you implemented difficulty topics in your project. Use the link button in the top right when you select a cell to get a **hyperlink**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1jBlYLxQcNV"
      },
      "source": [
        "---\n",
        "\n",
        "## Topic 1: **Imbalance Data**\n",
        "\n",
        "**Hyperlink:** [lifestyle_project_v4.ipynb](lifestyle_project_v4.ipynb#4.4-Handling-Class-Imbalance-with-SMOTE)\n",
        "\n",
        "\n",
        "### **Implementation & Rationale**\n",
        "\n",
        "#### **Rationale**\n",
        "Our dataset's target variable, `disease_risk`, was significantly imbalanced, with far fewer high-risk cases than low-risk ones (e.g., a 90/10 split). Training standard models on such skew often leads to a bias toward the majority class (healthy), resulting in poor sensitivity (recall) for the minority class (high risk). In a medical context, missing a high-risk patient (False Negative) is a critical error compared to flagging a healthy one (False Positive).\n",
        "\n",
        "#### **Implementation Strategy**\n",
        "We implemented **SMOTE (Synthetic Minority Over-sampling Technique)** using the `imblearn` library. Crucially, we applied SMOTE **only to the training split** to prevent data leakage (synthesizing validation data would artificially inflate scores). This synthesized new examples for the minority class by interpolating between existing ones, balancing the class distribution for training.\n",
        "\n",
        "#### **Pseudocode / Steps**\n",
        "```python\n",
        "# 1. Split Data to preventing leakage\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
        "\n",
        "# 2. Initialize SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# 3. Resample ONLY the training data (Never touch validation data!)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# 4. Check new class distribution\n",
        "print(y_train_resampled.value_counts()) # Should be balanced 50/50\n",
        "\n",
        "# 5. Train model on resampled data\n",
        "model.fit(X_train_resampled, y_train_resampled)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUfPpvutQyA3"
      },
      "source": [
        "---\n",
        "\n",
        "## Topic 2: **Feature Selection**\n",
        "\n",
        "**Hyperlink:** [lifestyle_project_v4.ipynb](lifestyle_project_v4.ipynb#4.4-Feature-Importance-Analysis-(Mutual-Information))\n",
        "\n",
        "### **Implementation & Rationale**\n",
        "\n",
        "#### **Rationale**\n",
        "Our dataset contained multiple lifestyle and physiological features, some of which could be redundant (multicollinearity) or noisy. Including irrelevant features increases model complexity (\"curse of dimensionality\"), risks overfitting, and reduces interpretability. We needed to identify which specific factors (e.g., Steps vs. Sleep) truly drive disease risk to simplify the model and explain it to clinicians.\n",
        "\n",
        "#### **Implementation Strategy**\n",
        "We utilized **Mutual Information (MI)** from `sklearn.feature_selection`. Unlike simple correlation (which only captures linear relationships like `y = mx + b`), MI captures non-linear dependencies between features and the target. For example, BMI might only be risky above a certain threshold, which correlation might miss but MI captures. We calculated MI scores on the balanced training set to ensure the importance of minority-class predictors was not drowned out.\n",
        "\n",
        "#### **Pseudocode / Steps**\n",
        "```python\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "# 1. Calculate Mutual Information scores\n",
        "mi_scores = mutual_info_classif(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# 2. Create a dataframe for visualization\n",
        "mi_df = pd.DataFrame({'Feature': X.columns, 'Score': mi_scores})\n",
        "mi_df = mi_df.sort_values(by='Score', ascending=False)\n",
        "\n",
        "# 3. Visualize to decide importance\n",
        "plt.barh(mi_df['Feature'], mi_df['Score'])\n",
        "plt.title(\"Mutual Information Scores\")\n",
        "plt.show()\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMWIG0EXQ3sa"
      },
      "source": [
        "---\n",
        "\n",
        "## Topic 3: **Ensemble Models**\n",
        "\n",
        "**Hyperlink:** [lifestyle_project_v4.ipynb](lifestyle_project_v4.ipynb#5.2-Challenger-Model-Tuned-Random-Forest)\n",
        "\n",
        "### **Implementation & Rationale**\n",
        "\n",
        "#### **Rationale**\n",
        "Single estimators (like a Decision Tree) often suffer from high variance (overfitting specific data points). We chose **Random Forest**, an ensemble of decision trees, for its robustness and predictive power. Medical risk factors often behave as \"step-functions\" (e.g., risk doesn't increase linearly with BP, but spikes after 140/90), which trees handle well. By averaging multiple trees (Bagging), Random Forest reduces the variance of individual trees and provides more stable probability estimates.\n",
        "\n",
        "#### **Implementation Strategy**\n",
        "We implemented a **Hyperparameter-Tuned Random Forest**. rather than using default settings, we used `RandomizedSearchCV` to explore a grid of parameters (`n_estimators`, `max_depth`, `min_samples_split`). This allowed us to find a model configuration that balanced complexity (depth) and generalization (estimators), ensuring we didn't just memorize the training data.\n",
        "\n",
        "#### **Pseudocode / Steps**\n",
        "```python\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# 1. Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# 2. Initialize Randomized Search\n",
        "rf_random = RandomizedSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42),\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=10,\n",
        "    cv=3,\n",
        "    scoring='recall' # Optimizing for sensitivity\n",
        ")\n",
        "\n",
        "# 3. Fit to resampled training data\n",
        "rf_random.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# 4. Evaluate best model params\n",
        "print(rf_random.best_params_)\n",
        "best_model = rf_random.best_estimator_\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "topic4_tuning"
      },
      "source": [
        "---\n",
        "\n",
        "## Topic 4: **Threshold Tuning & Business Logic**\n",
        "\n",
        "**Hyperlink:** [lifestyle_project_v4.ipynb](lifestyle_project_v4.ipynb#5.5-Strategic-Fix-Threshold-Tuning-for-Recall)\n",
        "\n",
        "### **Implementation & Rationale**\n",
        "\n",
        "#### **Rationale**\n",
        "Standard classifiers use a default probability threshold of 0.50 to classify a positive case. However, in medicine, the cost of a False Negative (missing specific disease) is often higher than a False Positive. But simply maximizing recall can lead to \"alarm fatigue\" where too many healthy people are flagged. We needed to find a custom threshold that balanced these trade-offs according to our specific business goal: creating a **High-Credibility Screening Tool**.\n",
        "\n",
        "#### **Implementation Strategy**\n",
        "We analyzed the Precision-Recall trade-off by varying the decision threshold from 0.0 to 1.0. We discovered that lowering the threshold to 0.15 maximized sensitivity but flagged 97% of healthy people as sick (low precision). We made a strategic decision to keep the threshold near 0.50 to prioritize **High Specificity (Precision)**. This means the model acts as a \"High Certainty\" filter: it may not catch every case, but when it *does* flag someone, clinicians can trust the alert.\n",
        "\n",
        "#### **Pseudocode / Steps**\n",
        "```python\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "# 1. Get probability scores instead of hard classes\n",
        "y_scores = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 2. Calculate Precision & Recall for all thresholds\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "# 3. Analyze Trade-offs (Visual Inspection)\n",
        "def plot_pr_curve(precisions, recalls):\n",
        "    plt.plot(recalls, precisions)\n",
        "    plt.xlabel('Recall (Sensitivity)')\n",
        "    plt.ylabel('Precision (Credibility)')\n",
        "\n",
        "# 4. Select Custom Threshold (e.g., 0.50 for high credibility)\n",
        "custom_threshold = 0.50\n",
        "y_custom_pred = (y_scores >= custom_threshold).astype(int)\n",
        "\n",
        "# 5. Evaluate final business metrics\n",
        "print(classification_report(y_test, y_custom_pred))\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
